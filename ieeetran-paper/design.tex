\section{Instrumentation}

There are two main challenges on tracing a process' progress with binary instrumentation
in production systems. One is the performance issue. Even a lightweight static binary
instrumentation usually increases execution time by tens of percents. The other one is
progress accuracy. The ideal progress tracing is uniform along the real execution, which
means that it can estimate accurately how much the task has been done and how long it will
still last. Take downloading a file for example. If the downloading progress bar shows a
50\% completion after 1 minute, it is clear that half of the task has been done and it may
last another 1 minute with a stable network connection. But for a compute-intensive
process, we can only know the process has met which tracepoint we instrumented. We can
never know the actions of the process that have no instrumented tracepoints, and the same
to the subsequent actions of the process. In a word, the progress of a compute-intensive
process that is not related to data I/O is hard to estimate.

We primarily concern the performance of tracing in $NO^2$'s instrumentation, and then
overcome the accuracy issue with our outlier clustering method that does not rely on
accurate estimation of progress, which will be discussed in the next section.

With much case study, we have had two simple observations on binary code runtime
behaviors. Functions in a binary can be placed on different levels of an abstract syntax
tree (AST). Functions on the same level of AST are often called at similar frequency, and
the minority of functions on the low level of AST consumes the majority of execution time,
mostly following a Pareto principle (80/20 principle). Table \ref{table:inst-stats} shows
the statistics of function hits of the instrumented ImageMagick dynamic link library.
There are 1060 functions in the library and only 33 functions called more than 10,000
times in five executions.

\begin{table}[h]
\caption{Statistics of function hits of ImageMagick}
\label{table:inst-stats}
\begin{center}
\begin{tabular}{r|r|l}
\hline
Hits & Functions & Example \\
\hline
above $10^7$ & 6 & CopyMagickMemory \\
$10^6$ - $10^7$ & 16 & GetCacheNexus \\
$10^5$ - $10^6$ & 2 & LocaleCompare \\
$10^4$ - $10^5$ & 9 & GetNexus \\
$10^3$ - $10^4$ & 10 & AddValueToSplayTree \\
$10^2$ - $10^3$ & 17 & FormatMagickStringList \\
$10^1$ - $10^2$ & 78 & NewSplayTree \\
$0$    - $10^1$ & 922 & GaussianBlurImage \\
\hline
\end{tabular}
\end{center}
Note: Only one function of each order of magnitude is shown in the table for example.
\end{table}

As we know, the entry/exit points of functions and basic blocks are commonly used
instrument points. For the purpose of progress tracing, a naive idea is to instrument with
each entry and exit point of all functions and basic blocks. Apparently, the overhead is
proportional to the hit rates. So with a little more coarse-grained instrumentation, we
can skip the minority of functions but reduce the majority of overheads. Aimed at
extremely little overheads, we proposed a function hit-statistics based instrument
approach. This goal has been achieved as the evaluation section shows.

The instrument point selector is designed to record each function call and maintains the
function hits statistics, which are saved in a key-value pattern: function name, number of
calls. After several runs, different AST levels of functions can be distinguished
according to the function hits. The instrumenter first loads the statistics data and
calculates the mean of hit numbers of all functions. Then it inserts a code snippet at
entries of each function, but skips those with a larger number of hits than the mean.
While the mean of all function hits is the default threshold and works well, a customized
threshold can be set. With the automatic selection, the instrumenter can instrument the
binary codes in an appropriate granularity. The instrumented binary is written back as
another file and sent to the ProActive scheduler to execute.

\section{Outlier Clustering}

For speculative executions, the first thing for $NO^2$ to do is finding out the outliers.
With the traces returned by the instrumented processes, $NO^2$ use an approach based on
Kmeans Clustering algorithm, which is commonly used in statistics analysis and data
mining, to hunt the outliers. With outliers exposed, $NO^2$ performs speculative
executions, which needs to interact with the job scheduler.

There are several assumptions for the outliers clustering.

\begin{itemize}
\item Outliers is the minority of the massive parallel processes.
\item The tasks are split with a small amount of imbalance.
\item The server nodes of cluster becomes abnormal indeterminately and may return to
normal after a while.
\end{itemize}

We novelly select two property of each process's traces to make outliers exposed, the
number of tracepoints have been met $N$ and the increment of tracepoints in one interval
$I$. Figure \ref{figure:executionsexample} shows a possible example of two processes of
the same binary code with same input at runtime, ideally they should draw the same line,
but process B is actually slower than process A. It is similar to the accuracy test of
instrumentation in the evaluation section.

\begin{figure}
\centering
\includegraphics[width=0.9\columnwidth]{figures/executions_example.eps}
\caption{Tracepoints of two example executions}
\label{figure:executionsexample}
\end{figure}

A naive idea for exposing outliers is generating two clusterings using a one-degree Kmeans
Clustering algorithm with all processes' number of tracepoints, and if the normalized
variation of the two clusterings' means is larger than a threshold $T$, the clustering of
processes with a mean value of $N$ less than the other one will be judged as outliers.

But the number of tracepoints is increased unevenly. We have mentioned this dilemma at the
instrumentation section. Four difference of two processes' number of tracepoints has been
marked as $d_1, d_2, d_3, d_4$ at four different time point. Although process B is always
0.8X slower than process A, the difference of process A and process B is not increased
along the whole time line. An obvious case is $d_1 > d_2$, this may lead to the naive
kmeans clustering approach missing process B when clustering outliers. Another type of
mistake is some conditions just as $d_3 < d_4$, process B may be just a little slower than
process A, but judged as an outlier in the naive kmeans clustering approach. So there no
fixed threshold $T$ is appropriate for judging the outliers with the naive kmeans
clustering approach.

To eliminate the mistake caused by false positive and false negative, an improved approach
has been proposed in $NO^2$. We proposed a new dynamic threshold $T_d$, which is
determined by the threshold $T$, the mean of all processes' tracepoints increment $I_m$
and the $i$th process's tracepoints increment $I_i$.

$$T_d = T \cdot (I_m / I_i)$$

As one of the assumptions is that outliers is the minority, the mean of the increment of
tracepoints of all processes $I_m$ is nearly the same to the majority. When the variance
of the means of clusterings decreased exceptionally like the case $d_1 > d_2$, the dynamic
threshold $T_d$ decreased correspondingly. When the variance of the means of clusterings
increased exceptionally like the case $d_3 < d_4$, the corresponding increase of $T_d$
comes along. So dynamic threshold $T_d$ can be adaptive to the uneven increase of number
of tracepoints generally. With this improvement approach for outliers clustering, $NO^2$
can find out most of outliers but introduce little false positive. 
